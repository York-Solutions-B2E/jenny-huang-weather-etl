{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file runs the program all at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import tarfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sql\n",
    "from pyquery import PyQuery as pq\n",
    "from urllib import request as urlreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpt = 'https://www.ncei.noaa.gov/data/global-summary-of-the-day/archive/'\n",
    "req = requests.get(endpt)\n",
    "html = pq(req.text)     #turn page into html for parsing using pyquery\n",
    "html_lst = list(html.items('a'))[5:]       #only get the links to the .gz files, ignore header etc\n",
    "\n",
    "os.mkdir(\"./temp\")  #make temp storage directory for csvs\n",
    "os.mkdir(\"./raw_data\")      #make directory to store yearly extracted data\n",
    "#append links to list\n",
    "links = []\n",
    "for l in html_lst:\n",
    "    links.append(str(l).split('\"')[1])\n",
    "\n",
    "#only get 1950 - 2000\n",
    "links = links[links.index('1950.tar.gz'): links.index('2000.tar.gz')+1]\n",
    "\n",
    "#PARSE ALL DATA IN LINKS \n",
    "for l in links:\n",
    "    #open gzip to temp dir\n",
    "    temp_end = f\"{endpt}{l}\"\n",
    "    response = requests.get(temp_end, stream=True)\n",
    "    file = tarfile.open(fileobj=response.raw, mode=\"r|gz\")\n",
    "    file.extractall(path = \"./temp\")\n",
    "\n",
    "    #move data from each csv  to dataframe then delete csv\n",
    "    df = pd.DataFrame()\n",
    "    for filename in os.listdir(\"./temp\"):\n",
    "        if not (filename[0] == \"7\" or filename[:2] == \"69\"):\n",
    "            continue\n",
    "        temp = pd.read_csv(f\"./temp/{filename}\")\n",
    "        if temp[\"LATITUDE\"].isnull().any() or temp[\"LONGITUDE\"].isnull().any():\n",
    "            os.remove(f\"./temp/{filename}\")\n",
    "            continue\n",
    "        (lat, long) = (float(temp[\"LATITUDE\"][0]), float(temp[\"LONGITUDE\"][0]))  #get location info\n",
    "        if lat > 49.4 or lat < 24.4 or long < -125 or long > -66.9: #rough estimate of US location -- rough filter \n",
    "            os.remove(f\"./temp/{filename}\")\n",
    "            continue\n",
    "        #edge cases -- check station name\n",
    "        if temp[\"NAME\"][0][-2:] != \"US\":\n",
    "            os.remove(f\"./temp/{filename}\")\n",
    "            continue\n",
    "        df = pd.concat([df, temp])\n",
    "        os.remove(f\"./temp/{filename}\")\n",
    "\n",
    "    #parse date and filter data\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    df[\"MONTH\"] = df[\"DATE\"].dt.month\n",
    "    df[\"YEAR\"] = df[\"DATE\"].dt.year\n",
    "    df = df[[\"NAME\", \"DATE\", \"YEAR\", \"MONTH\", \"TEMP\", \"DEWP\", \"MIN\", \"MAX\", \"PRCP\", \"SNDP\"]]\n",
    "    \n",
    "    #export raw data as csv\n",
    "    df.to_csv(f\"./raw_data/{l[:4]}_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in sorted(os.listdir(\"./raw_data\")):\n",
    "    df = pd.read_csv(f\"./raw_data/{filename}\")\n",
    "    \n",
    "    #for each variable, create a temp dataset removing null values\n",
    "    final = pd.DataFrame()\n",
    "    #for temp\n",
    "    df_temp = df[df[\"TEMP\"] != 9999.9]\n",
    "    grouped = df_temp.copy().groupby(\"MONTH\").agg({'TEMP' : ['mean', 'median']})\n",
    "    grouped.columns = [f'{col[0]}_{col[1]}' for col in grouped.columns]\n",
    "    grouped = grouped.reset_index()\n",
    "    final[\"MONTH\"] = grouped[\"MONTH\"]\n",
    "    final[\"YEAR\"] = filename[:4]\n",
    "    final[[\"TEMP_mean\", \"TEMP_median\"]] = grouped[[\"TEMP_mean\", \"TEMP_median\"]]\n",
    "    final[\"TEMP_var\"] = df_temp.groupby(\"MONTH\")[\"TEMP\"].var().reset_index(drop = True)\n",
    "    #min temp\n",
    "    df_temp = df[df[\"MIN\"] != 9999.9]\n",
    "    grouped = df_temp.copy().groupby(\"MONTH\").agg({'MIN' : ['min']})\n",
    "    grouped.columns = [f'{col[0]}_{col[1]}' for col in grouped.columns]\n",
    "    grouped = grouped.reset_index()\n",
    "    final[\"TEMP_min\"] = grouped[\"MIN_min\"]\n",
    "    #max temp\n",
    "    df_temp = df[df[\"MAX\"] != 9999.9]\n",
    "    grouped = df_temp.copy().groupby(\"MONTH\").agg({'MAX' : ['max']})\n",
    "    grouped.columns = [f'{col[0]}_{col[1]}' for col in grouped.columns]\n",
    "    grouped = grouped.reset_index()\n",
    "    final[\"TEMP_max\"] = grouped[\"MAX_max\"]\n",
    "    #precip\n",
    "    df_temp = df[df[\"PRCP\"] != 99.99]\n",
    "    grouped = df_temp.copy().groupby(\"MONTH\").agg({'PRCP' : ['mean', 'median', 'min', 'max']})\n",
    "    grouped.columns = [f'{col[0]}_{col[1]}' for col in grouped.columns]\n",
    "    grouped = grouped.reset_index()\n",
    "    final[[\"PRCP_mean\", \"PRCP_median\", \"PRCP_min\", \"PRCP_max\"]] = grouped[[\"PRCP_mean\", \"PRCP_median\", \"PRCP_min\", \"PRCP_max\"]]\n",
    "    final[\"PRCP_var\"] = df_temp.groupby(\"MONTH\")[\"PRCP\"].var().reset_index(drop = True)\n",
    "        \n",
    "    if int(filename[:4]) == 1950:\n",
    "        final.to_csv('monthly_weather_stats.csv', mode='w', index=False, header=True)     #write to CSV with header if it's the first file\n",
    "    else:\n",
    "        final.to_csv('monthly_weather_stats.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = sql.create_engine(\n",
    "        'postgresql://postgres:password@localhost:5432/postgres')\n",
    "\n",
    "df = pd.read_csv(\"monthly_weather_stats.csv\")\n",
    "with e.begin() as connection:\n",
    "    df.to_sql(\"monthly_weather\", con=connection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
