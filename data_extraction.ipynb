{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This file is for the downloading and extraction of all data files from 1950 - 2000 from the NOAA database.\n",
    "* All non-contiguous-USA datafiles are ignored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import tarfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyquery import PyQuery as pq\n",
    "from urllib import request as urlreq\n",
    "import reverse_geocoder as rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpt = 'https://www.ncei.noaa.gov/data/global-summary-of-the-day/archive/'\n",
    "req = requests.get(endpt)\n",
    "html = pq(req.text)     #turn page into html for parsing using pyquery\n",
    "html_lst = list(html.items('a'))[5:]       #only get the links to the .gz files, ignore header etc\n",
    "\n",
    "#append links to list\n",
    "links = []\n",
    "for l in html_lst:\n",
    "    links.append(str(l).split('\"')[1])\n",
    "\n",
    "#only get 1950 - 2000\n",
    "links = links[links.index('1950.tar.gz'): links.index('2000.tar.gz')+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARSE ALL DATA IN LINKS \n",
    "for l in links:\n",
    "    #open gzip to temp dir\n",
    "    temp_end = f\"{endpt}{l}\"\n",
    "    response = requests.get(temp_end, stream=True)\n",
    "    file = tarfile.open(fileobj=response.raw, mode=\"r|gz\")\n",
    "    file.extractall(path = \"./temp\")\n",
    "\n",
    "    #move data from each csv  to dataframe then delete csv\n",
    "    df = pd.DataFrame()\n",
    "    for filename in os.listdir(\"./temp\"):\n",
    "        temp = pd.read_csv(f\"./temp/{filename}\")\n",
    "        if temp[\"LATITUDE\"].isnull().any() or temp[\"LONGITUDE\"].isnull().any():\n",
    "            os.remove(f\"./temp/{filename}\")\n",
    "            continue\n",
    "        (lat, long) = (float(temp[\"LATITUDE\"][0]), float(temp[\"LONGITUDE\"][0]))  #get location info\n",
    "        if lat > 49.4 or lat < 24.4 or long < -125 or long > -66.9: #rough estimate of US location -- rough filter \n",
    "            os.remove(f\"./temp/{filename}\")\n",
    "            continue\n",
    "        #edge cases -- check station name\n",
    "        if temp[\"NAME\"][0][-2:] != \"US\":\n",
    "            os.remove(f\"./temp/{filename}\")\n",
    "            continue\n",
    "    # loc = rg.search((lat, long))[0]\n",
    "    # if loc['cc'] != 'US':\n",
    "    #     os.remove(f\"./temp/{filename}\")\n",
    "    #     continue\n",
    "    # if loc['admin1'] == 'Hawaii' or loc['admin1'] == 'Alaska':\n",
    "    #     os.remove(f\"./temp/{filename}\")\n",
    "    #     continue\n",
    "        df = pd.concat([df, temp])\n",
    "        os.remove(f\"./temp/{filename}\")\n",
    "\n",
    "    #parse date and filter data\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    df[\"MONTH\"] = df[\"DATE\"].dt.month\n",
    "    df[\"YEAR\"] = df[\"DATE\"].dt.year\n",
    "    df = df[[\"NAME\", \"DATE\", \"YEAR\", \"MONTH\", \"TEMP\", \"DEWP\", \"MIN\", \"MAX\", \"PRCP\", \"SNDP\"]]\n",
    "    \n",
    "    #export raw data as csv\n",
    "    df.to_csv(f\"./raw_data/{l[:4]}_raw.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
